{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Nuts & Bolts of Machine Learning For more projects visit Github Blogs 1. Setting Up Ubuntu System for Deep Learning 2. Useful Deep Learning Libraries 3. Keyword Extraction","title":"Home"},{"location":"#nuts-bolts-of-machine-learning","text":"For more projects visit Github","title":"Nuts &amp; Bolts of Machine Learning"},{"location":"#blogs","text":"","title":"Blogs"},{"location":"#1-setting-up-ubuntu-system-for-deep-learning","text":"","title":"1. Setting Up Ubuntu System for Deep Learning"},{"location":"#2-useful-deep-learning-libraries","text":"","title":"2. Useful Deep Learning Libraries"},{"location":"#3-keyword-extraction","text":"","title":"3. Keyword Extraction"},{"location":"about/","text":"About Sachin Umrao Hello World! This is Sachin. After finishing my masters in mechanical engineering, I am currently working as Lead Data Scientist at at Fidelity Investments, Bengaluru. In my leisure time, I like to read about machine learning and watch tv series. You can find me @ Twitter Reddit LinkedIn Github or just drop a mail @ sachin.umrao.1512@gmail.com Ananthagiri Hills, Aug 2019","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#sachin-umrao","text":"Hello World! This is Sachin. After finishing my masters in mechanical engineering, I am currently working as Lead Data Scientist at at Fidelity Investments, Bengaluru. In my leisure time, I like to read about machine learning and watch tv series. You can find me @ Twitter Reddit LinkedIn Github or just drop a mail @ sachin.umrao.1512@gmail.com Ananthagiri Hills, Aug 2019","title":"Sachin Umrao"},{"location":"projects/","text":"Nuts & Bolts of Machine Learning 1. NLP Projcts 2. Computer Vision Projects 3. Reinforcement Learning Projects 4. Time Series Projects 5. Django Projects","title":"Projects"},{"location":"projects/#nuts-bolts-of-machine-learning","text":"","title":"Nuts &amp; Bolts of Machine Learning"},{"location":"projects/#1-nlp-projcts","text":"","title":"1. NLP Projcts"},{"location":"projects/#2-computer-vision-projects","text":"","title":"2. Computer Vision Projects"},{"location":"projects/#3-reinforcement-learning-projects","text":"","title":"3. Reinforcement Learning Projects"},{"location":"projects/#4-time-series-projects","text":"","title":"4. Time Series Projects"},{"location":"projects/#5-django-projects","text":"","title":"5. Django Projects"},{"location":"blogs/dl_libs/","text":"Nuts & Bolts of Machine Learning For more projects visit Github Useful Deep Learning Libraries Image Credit: https://www.analyticsindiamag.com If you are a new to the field of machine learning, you can get overwhelmed with the variety of sub-fields available under the umbrella of machine learning. For each subfield, there are specific libraries to help you with getting the task done. In this blog, we will glance over the different libraries and their use cases. General Purpose Machine Learning Libraries Scikit-Learn Scitkit-learn provides all popular machine learning algorithms and functions for data transformation to error analysis pre-built into it. It is a recommended library for getting started with machine learning. One can tweak the parameters in algortihms and see the changes in the performance of model. Tensorflow Most of the people take tensorflow as deep learning library but at its core it just converts mathematical operations into a computational grpahs. Hence, any machine learning algorithm can be developed in tensorlfow. The implementations of Logistic Regression and Linear Regression in tensorlfow can be easily found in web. Working with Videos/Images OpenCV OpenCV is the most popular library for working with images and videos. It provides all basic operations to be executed on images. It enables us to control webcam and take images or video-feed from it. Hence, it becomes suitable for live projects of object detection, face recognition etc. Scikit-Image It provides optimized image transformation operations. DLib It provides deep learning based implementations for face detection and object detection. Working with Text Data NLTK NLTK (Natural Language TooKit) provides basic operations for text pre-processing. Spacy Spacy provides all text pre-processing functions along with deep learning based models for various NLP tasks. Stanford-NLP It is developed in Stanford as evidnet from name. It is a cutting edge library which features latest developments in the field of NLP. Gensim Gensim contains various trained models for word-embeddings and topic-modelling. Reinforcement Learning OpenAI Gym For most of reinforcement leraning tasks, an enviornment is required where agent can perform actions and learn. Gym provides various environments where one can train agents. The environment includes atari games, robotic simulations and alot of other fancy things. PyGame If you want to create a new environment (or a new game) and train agent in it, you can build it with PyGame. Keras-RL Keras-RL is deep reinforcement learning library. It provides deep architectures which can be trained in Gym or other environment. It features popular algorithms such as DQN. Deep Learning Libraries Theano Theano was developed by MILA and it is predecessor of all deep learning frameworks. But now MILA has stopped its development after 1.0 release. Tensorflow Tensorflow is the most popular library for machine learning. It emphasized on the concept of computational graphs. It is well suited for distributed computing. It is supported by Google. Pytorch Pytorch is being developed by Facebook and it is the main rival of Tensorflow. Pytorch also provides a dynamic graph execution. Keras Keras is a high-level wrapper on existing deep learning frameworks. It supports theano, tensorflow and mxnet as its backends. It is recommended for beginners as deep learning architectures can be made very easily, quickly and without in-depth knowledge of neural networks. Other Deep Learning Libraries:- H2O Supported by H2O.ai which provide several deep learning solutions such as Driverless AI Caffe It was originally developed by Berkley AI Research (BAIR) group, but now it is advanced by Facebook CNTK A deep learning library provided by Microsift MXNet MXNet is supported by Amazon Most of the deep learing libraries have two different versions for CPU and GPU. The GPU version of the library takes advantage of CUDA acceleration and performance gain is enormous. So, if you have Nvidia graphics card, setup CUDA and install gpu version of the library. Other Supporting Libraries Numpy Numpy is a library for processing numerical data. It is useful in data pre-processing step. It gives good performance when vectorization is used. It also provides very optimized implementations of common mathematical operations. Pandas Pandas is used for mix data as it can handle strings and numerical data as well. Several useful transformations are already implemented (such as fixing null values, one-hot encoding) and easily handles datetime data. It has become popular for data preprocessing. Scipy Scipy provides complex mathematical operations such as convolution and matrix inversions along with various statistical functions. It also serves as backend of Scikit-Learn and Scikit-Image. Matplotlib Matplotlib is most popular library for data visualization. Data visualization is helpful in analyzing the data during EDA (Exploratory Data Analysis). Other popular libraries for data visualization:- Bokeh, Plotly, Seaborn, Graphviz","title":"Nuts & Bolts of Machine Learning"},{"location":"blogs/dl_libs/#nuts-bolts-of-machine-learning","text":"For more projects visit Github","title":"Nuts &amp; Bolts of Machine Learning"},{"location":"blogs/dl_libs/#useful-deep-learning-libraries","text":"Image Credit: https://www.analyticsindiamag.com If you are a new to the field of machine learning, you can get overwhelmed with the variety of sub-fields available under the umbrella of machine learning. For each subfield, there are specific libraries to help you with getting the task done. In this blog, we will glance over the different libraries and their use cases.","title":"Useful Deep Learning Libraries"},{"location":"blogs/dl_libs/#general-purpose-machine-learning-libraries","text":"","title":"General Purpose Machine Learning Libraries"},{"location":"blogs/dl_libs/#scikit-learn","text":"Scitkit-learn provides all popular machine learning algorithms and functions for data transformation to error analysis pre-built into it. It is a recommended library for getting started with machine learning. One can tweak the parameters in algortihms and see the changes in the performance of model.","title":"Scikit-Learn"},{"location":"blogs/dl_libs/#tensorflow","text":"Most of the people take tensorflow as deep learning library but at its core it just converts mathematical operations into a computational grpahs. Hence, any machine learning algorithm can be developed in tensorlfow. The implementations of Logistic Regression and Linear Regression in tensorlfow can be easily found in web.","title":"Tensorflow"},{"location":"blogs/dl_libs/#working-with-videosimages","text":"","title":"Working with Videos/Images"},{"location":"blogs/dl_libs/#opencv","text":"OpenCV is the most popular library for working with images and videos. It provides all basic operations to be executed on images. It enables us to control webcam and take images or video-feed from it. Hence, it becomes suitable for live projects of object detection, face recognition etc.","title":"OpenCV"},{"location":"blogs/dl_libs/#scikit-image","text":"It provides optimized image transformation operations.","title":"Scikit-Image"},{"location":"blogs/dl_libs/#dlib","text":"It provides deep learning based implementations for face detection and object detection.","title":"DLib"},{"location":"blogs/dl_libs/#working-with-text-data","text":"","title":"Working with Text Data"},{"location":"blogs/dl_libs/#nltk","text":"NLTK (Natural Language TooKit) provides basic operations for text pre-processing.","title":"NLTK"},{"location":"blogs/dl_libs/#spacy","text":"Spacy provides all text pre-processing functions along with deep learning based models for various NLP tasks.","title":"Spacy"},{"location":"blogs/dl_libs/#stanford-nlp","text":"It is developed in Stanford as evidnet from name. It is a cutting edge library which features latest developments in the field of NLP.","title":"Stanford-NLP"},{"location":"blogs/dl_libs/#gensim","text":"Gensim contains various trained models for word-embeddings and topic-modelling.","title":"Gensim"},{"location":"blogs/dl_libs/#reinforcement-learning","text":"","title":"Reinforcement Learning"},{"location":"blogs/dl_libs/#openai-gym","text":"For most of reinforcement leraning tasks, an enviornment is required where agent can perform actions and learn. Gym provides various environments where one can train agents. The environment includes atari games, robotic simulations and alot of other fancy things.","title":"OpenAI Gym"},{"location":"blogs/dl_libs/#pygame","text":"If you want to create a new environment (or a new game) and train agent in it, you can build it with PyGame.","title":"PyGame"},{"location":"blogs/dl_libs/#keras-rl","text":"Keras-RL is deep reinforcement learning library. It provides deep architectures which can be trained in Gym or other environment. It features popular algorithms such as DQN.","title":"Keras-RL"},{"location":"blogs/dl_libs/#deep-learning-libraries","text":"","title":"Deep Learning Libraries"},{"location":"blogs/dl_libs/#theano","text":"Theano was developed by MILA and it is predecessor of all deep learning frameworks. But now MILA has stopped its development after 1.0 release.","title":"Theano"},{"location":"blogs/dl_libs/#tensorflow_1","text":"Tensorflow is the most popular library for machine learning. It emphasized on the concept of computational graphs. It is well suited for distributed computing. It is supported by Google.","title":"Tensorflow"},{"location":"blogs/dl_libs/#pytorch","text":"Pytorch is being developed by Facebook and it is the main rival of Tensorflow. Pytorch also provides a dynamic graph execution.","title":"Pytorch"},{"location":"blogs/dl_libs/#keras","text":"Keras is a high-level wrapper on existing deep learning frameworks. It supports theano, tensorflow and mxnet as its backends. It is recommended for beginners as deep learning architectures can be made very easily, quickly and without in-depth knowledge of neural networks.","title":"Keras"},{"location":"blogs/dl_libs/#other-deep-learning-libraries-","text":"","title":"Other Deep Learning Libraries:-"},{"location":"blogs/dl_libs/#h2o","text":"Supported by H2O.ai which provide several deep learning solutions such as Driverless AI","title":"H2O"},{"location":"blogs/dl_libs/#caffe","text":"It was originally developed by Berkley AI Research (BAIR) group, but now it is advanced by Facebook","title":"Caffe"},{"location":"blogs/dl_libs/#cntk","text":"A deep learning library provided by Microsift","title":"CNTK"},{"location":"blogs/dl_libs/#mxnet","text":"MXNet is supported by Amazon Most of the deep learing libraries have two different versions for CPU and GPU. The GPU version of the library takes advantage of CUDA acceleration and performance gain is enormous. So, if you have Nvidia graphics card, setup CUDA and install gpu version of the library.","title":"MXNet"},{"location":"blogs/dl_libs/#other-supporting-libraries","text":"","title":"Other Supporting Libraries"},{"location":"blogs/dl_libs/#numpy","text":"Numpy is a library for processing numerical data. It is useful in data pre-processing step. It gives good performance when vectorization is used. It also provides very optimized implementations of common mathematical operations.","title":"Numpy"},{"location":"blogs/dl_libs/#pandas","text":"Pandas is used for mix data as it can handle strings and numerical data as well. Several useful transformations are already implemented (such as fixing null values, one-hot encoding) and easily handles datetime data. It has become popular for data preprocessing.","title":"Pandas"},{"location":"blogs/dl_libs/#scipy","text":"Scipy provides complex mathematical operations such as convolution and matrix inversions along with various statistical functions. It also serves as backend of Scikit-Learn and Scikit-Image.","title":"Scipy"},{"location":"blogs/dl_libs/#matplotlib","text":"Matplotlib is most popular library for data visualization. Data visualization is helpful in analyzing the data during EDA (Exploratory Data Analysis).","title":"Matplotlib"},{"location":"blogs/dl_libs/#other-popular-libraries-for-data-visualization-","text":"Bokeh, Plotly, Seaborn, Graphviz","title":"Other popular libraries for data visualization:-"},{"location":"blogs/keywords_extraction/","text":"Nuts & Bolts of Machine Learning For more projects visit Github Keyword Extraction Image Credit: www.adaringadventure.com Keyword Extraction using RAKE 1. Why perform keyword extraction? Reduces the dimensionality of text Find summery of text ( What this documents is about? ) Fetch similar documents in Information Retrieval System Classify Documents when there are large number of categories 2. How to perform keyword extraction? I. Candidate Selection II. Property Calculation III. Scoring of potential keywords and final selection 3. Rapid Automatic Keyword Extraction (RAKE) Use punctuations and stopwords as boundaries. Keyword phrases are assumed to be lying between these boundaries ( in ideal case tokens should be stemmed as well before this step ). These words are often called Candidate Words/Phrases . RAKE computes the properties of each candidate, which is the sum of score for each word in phrase. The words are scored according to their frequency and typical length of candidate phrase in which they appear. Rank keywords based on RAKE score 4. Error Estimation Match keywords obtained from model with keywords hand assigned to the document. Precision : Percentage of correct keywords among those extracted Recal : Percentage of correctly extracted keywords among all correct ones Additional Notes Advantages of RAKE I. Doamin Independence II. Good Precision Scoring in RAKE Score(word) = Degree(word) / Frequency(word) Frequency(word) = Number of times word occurs in document Degree(word) = Similar to degree of node in a graph. It is number of times a certain word co-occurs with other candidate keyword","title":"Nuts & Bolts of Machine Learning"},{"location":"blogs/keywords_extraction/#nuts-bolts-of-machine-learning","text":"For more projects visit Github","title":"Nuts &amp; Bolts of Machine Learning"},{"location":"blogs/keywords_extraction/#keyword-extraction","text":"Image Credit: www.adaringadventure.com","title":"Keyword Extraction"},{"location":"blogs/keywords_extraction/#keyword-extraction-using-rake","text":"","title":"Keyword Extraction using RAKE"},{"location":"blogs/keywords_extraction/#1-why-perform-keyword-extraction","text":"Reduces the dimensionality of text Find summery of text ( What this documents is about? ) Fetch similar documents in Information Retrieval System Classify Documents when there are large number of categories","title":"1. Why perform keyword extraction?"},{"location":"blogs/keywords_extraction/#2-how-to-perform-keyword-extraction","text":"I. Candidate Selection II. Property Calculation III. Scoring of potential keywords and final selection","title":"2. How to perform keyword extraction?"},{"location":"blogs/keywords_extraction/#3-rapid-automatic-keyword-extraction-rake","text":"Use punctuations and stopwords as boundaries. Keyword phrases are assumed to be lying between these boundaries ( in ideal case tokens should be stemmed as well before this step ). These words are often called Candidate Words/Phrases . RAKE computes the properties of each candidate, which is the sum of score for each word in phrase. The words are scored according to their frequency and typical length of candidate phrase in which they appear. Rank keywords based on RAKE score","title":"3. Rapid Automatic Keyword Extraction (RAKE)"},{"location":"blogs/keywords_extraction/#4-error-estimation","text":"Match keywords obtained from model with keywords hand assigned to the document. Precision : Percentage of correct keywords among those extracted Recal : Percentage of correctly extracted keywords among all correct ones","title":"4. Error Estimation"},{"location":"blogs/keywords_extraction/#additional-notes","text":"","title":"Additional Notes"},{"location":"blogs/keywords_extraction/#advantages-of-rake","text":"I. Doamin Independence II. Good Precision","title":"Advantages of RAKE"},{"location":"blogs/keywords_extraction/#scoring-in-rake","text":"Score(word) = Degree(word) / Frequency(word) Frequency(word) = Number of times word occurs in document Degree(word) = Similar to degree of node in a graph. It is number of times a certain word co-occurs with other candidate keyword","title":"Scoring in RAKE"},{"location":"blogs/ubuntu_setup/","text":"Nuts & Bolts of Machine Learning For more projects visit Github Setting Up Ubuntu System for Deep Learning Image Credit: https://mytechshout.com As I started my journey to learn coding, I was introduced to Linux by my mentors. Primarily Linux was used by programmers but now a days it has garnered popularity in all domains. There are many Linux based operating systems available out there but Ubuntu has become most used UNIX based OS. It is widely used in industries and universities. In this blog we will discuss what applications and tools are required/suggested to setup in a fresh ubuntu installation for working on machine learning and deep learning projects. Update the System $ sudo apt update $ sudo apt upgrade Basic Utilities $ sudo apt install vim gedit-common $ sudo apt install ubuntu-restricted-extras $ sudo apt install vlc $ sudo apt install classicmenu-indicator $ sudo apt install redshift redshift-gtk $ sudo apt install terminator $ sudo apt install unity-tweak-tool Install Google Chrome from .deb package Notes and Others $ sudo apt install nixnote2 #(To connect with evernote) Install Simple Note from .deb package (Take notes in cross platform app) Download Medium Desk and extract it to /opt folder (Read blogs on medium) Development Tools $ sudo apt install gcc g++ $ sudo apt install cmake build-essential $ sudo apt install python-pip python-dev (for python3 use: python3-pip , python3-dev $ sudo apt install openjdk-8-jre $ sudo apt install git Text Editors Install Sublime Text3 from official site Download Menlo font (Its my favorite font but it is not available in Ubuntu, so you have to install opensource version) Install VS Code site Python for Data Science 1. Make Virtual Environment $ sudo apt install python-virtualenv $ mkdir ~/env_name && cd ~/env_name $ virtualenv env_name 2. Activate virtual environment $ source ~/env_name/bin/activate 3. Deactivate virtual environment $ deactivate Install Python Libraries $ pip install numpy matplotlib pandas $ pip install scipy scikit-learn scikit-image pillow $ pip install jupyter jupyterlab $ pip install nltk $ pip install spacy $ pip install tensorflow keras $ pip install xgboost Install CUDA 1. Install Nvidia Graphics Driver from Software & Updates Download cuda_x.deb packages Download cudnn_y.deb packages $ sudo dpkg -i cuda_x.deb $ sudo apt update $ sudo apt install cuda $ sudo apt upgrade 2. Add Cuda in Path Add following path to ~/.bashrc file export CUDA_HOME=/usr/local/cuda-x.y export LD_LIBRARY_PATH=${CUDA_HOME}/lib64 PATH=${CUDA_HOME}/bin:${PATH} export PATH (where x and y are release numbers e.g. 7.5 or 8.0) Now we need to install Nvidia\u2019s library for deep learning CuDNN for which you need to make developer\u2019s account in Nvidia. Download the required cuddnn*.deb file. $ sudo dpkg -i cudnn*.deb Install Deep Learning Frameworks $ sudo apt install cuda-command-line-tools Add following lines to the ~/.bashrc file export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64 Install Tensorflow-GPU $ sudo pip install tensorflow-gpu keras Install Pytorch from official site","title":"Nuts & Bolts of Machine Learning"},{"location":"blogs/ubuntu_setup/#nuts-bolts-of-machine-learning","text":"For more projects visit Github","title":"Nuts &amp; Bolts of Machine Learning"},{"location":"blogs/ubuntu_setup/#setting-up-ubuntu-system-for-deep-learning","text":"Image Credit: https://mytechshout.com As I started my journey to learn coding, I was introduced to Linux by my mentors. Primarily Linux was used by programmers but now a days it has garnered popularity in all domains. There are many Linux based operating systems available out there but Ubuntu has become most used UNIX based OS. It is widely used in industries and universities. In this blog we will discuss what applications and tools are required/suggested to setup in a fresh ubuntu installation for working on machine learning and deep learning projects.","title":"Setting Up Ubuntu System for Deep Learning"},{"location":"blogs/ubuntu_setup/#update-the-system","text":"$ sudo apt update $ sudo apt upgrade","title":"Update the System"},{"location":"blogs/ubuntu_setup/#basic-utilities","text":"$ sudo apt install vim gedit-common $ sudo apt install ubuntu-restricted-extras $ sudo apt install vlc $ sudo apt install classicmenu-indicator $ sudo apt install redshift redshift-gtk $ sudo apt install terminator $ sudo apt install unity-tweak-tool","title":"Basic Utilities"},{"location":"blogs/ubuntu_setup/#install-google-chrome-from-deb-package","text":"","title":"Install Google Chrome from .deb package"},{"location":"blogs/ubuntu_setup/#notes-and-others","text":"$ sudo apt install nixnote2 #(To connect with evernote)","title":"Notes and Others"},{"location":"blogs/ubuntu_setup/#install-simple-note-from-deb-package-take-notes-in-cross-platform-app","text":"","title":"Install Simple Note from .deb package (Take notes in cross platform app)"},{"location":"blogs/ubuntu_setup/#download-medium-desk-and-extract-it-to-opt-folder-read-blogs-on-medium","text":"","title":"Download Medium Desk and extract it to /opt folder (Read blogs on medium)"},{"location":"blogs/ubuntu_setup/#development-tools","text":"$ sudo apt install gcc g++ $ sudo apt install cmake build-essential $ sudo apt install python-pip python-dev (for python3 use: python3-pip , python3-dev $ sudo apt install openjdk-8-jre $ sudo apt install git","title":"Development Tools"},{"location":"blogs/ubuntu_setup/#text-editors","text":"Install Sublime Text3 from official site Download Menlo font (Its my favorite font but it is not available in Ubuntu, so you have to install opensource version)","title":"Text Editors"},{"location":"blogs/ubuntu_setup/#install-vs-code-site","text":"","title":"Install VS Code site"},{"location":"blogs/ubuntu_setup/#python-for-data-science","text":"","title":"Python for Data Science"},{"location":"blogs/ubuntu_setup/#1-make-virtual-environment","text":"$ sudo apt install python-virtualenv $ mkdir ~/env_name && cd ~/env_name $ virtualenv env_name","title":"1. Make Virtual Environment"},{"location":"blogs/ubuntu_setup/#2-activate-virtual-environment","text":"$ source ~/env_name/bin/activate","title":"2. Activate virtual environment"},{"location":"blogs/ubuntu_setup/#3-deactivate-virtual-environment","text":"$ deactivate","title":"3. Deactivate virtual environment"},{"location":"blogs/ubuntu_setup/#install-python-libraries","text":"$ pip install numpy matplotlib pandas $ pip install scipy scikit-learn scikit-image pillow $ pip install jupyter jupyterlab $ pip install nltk $ pip install spacy $ pip install tensorflow keras $ pip install xgboost","title":"Install Python Libraries"},{"location":"blogs/ubuntu_setup/#install-cuda","text":"","title":"Install CUDA"},{"location":"blogs/ubuntu_setup/#1-install-nvidia-graphics-driver-from-software-updates","text":"Download cuda_x.deb packages Download cudnn_y.deb packages $ sudo dpkg -i cuda_x.deb $ sudo apt update $ sudo apt install cuda $ sudo apt upgrade","title":"1. Install Nvidia Graphics Driver from Software &amp; Updates"},{"location":"blogs/ubuntu_setup/#2-add-cuda-in-path","text":"Add following path to ~/.bashrc file export CUDA_HOME=/usr/local/cuda-x.y export LD_LIBRARY_PATH=${CUDA_HOME}/lib64 PATH=${CUDA_HOME}/bin:${PATH} export PATH (where x and y are release numbers e.g. 7.5 or 8.0) Now we need to install Nvidia\u2019s library for deep learning CuDNN for which you need to make developer\u2019s account in Nvidia. Download the required cuddnn*.deb file. $ sudo dpkg -i cudnn*.deb","title":"2. Add Cuda in Path"},{"location":"blogs/ubuntu_setup/#install-deep-learning-frameworks","text":"$ sudo apt install cuda-command-line-tools","title":"Install Deep Learning Frameworks"},{"location":"blogs/ubuntu_setup/#add-following-lines-to-the-bashrc-file","text":"export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64","title":"Add following lines to the ~/.bashrc file"},{"location":"blogs/ubuntu_setup/#install-tensorflow-gpu","text":"$ sudo pip install tensorflow-gpu keras","title":"Install Tensorflow-GPU"},{"location":"blogs/ubuntu_setup/#install-pytorch-from-official-site","text":"","title":"Install Pytorch from official site"}]}